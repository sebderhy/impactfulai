<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Risk Management | ImpactfulAI</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Risk Management" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Let’s make AI count as it should." />
<meta property="og:description" content="Let’s make AI count as it should." />
<link rel="canonical" href="https://sebderhy.github.io/impactfulai/2021/12/06/Risk-Management.html" />
<meta property="og:url" content="https://sebderhy.github.io/impactfulai/2021/12/06/Risk-Management.html" />
<meta property="og:site_name" content="ImpactfulAI" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-12-06T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://sebderhy.github.io/impactfulai/2021/12/06/Risk-Management.html","@type":"BlogPosting","headline":"Risk Management","dateModified":"2021-12-06T00:00:00-06:00","datePublished":"2021-12-06T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://sebderhy.github.io/impactfulai/2021/12/06/Risk-Management.html"},"description":"Let’s make AI count as it should.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/impactfulai/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://sebderhy.github.io/impactfulai/feed.xml" title="ImpactfulAI" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-9VJV0BP56W"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-9VJV0BP56W');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/impactfulai/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/impactfulai/">ImpactfulAI</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/impactfulai/about/">About Me</a><a class="page-link" href="/impactfulai/search/">Search</a><a class="page-link" href="/impactfulai/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Risk Management</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-12-06T00:00:00-06:00" itemprop="datePublished">
        Dec 6, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      14 min read
    
</span></p>

    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p><img src="https://sebderhy.github.io/impactfulai/assets/img/2021-12-06-Risk-Management/media/image1.png" alt="" /></p>

<p>One of the most important principles of the <a href="http://theleanstartup.com/principles"><span class="underline">Lean Startup methodology</span></a> is “fail fast”. No one wants to fail, but failing rapidly makes it less painful, and more importantly, leaves more time and resources to try something new until success.</p>

<p>Since AI projects share this characteristic that <a href="https://venturebeat.com/2019/07/19/why-do-87-of-data-science-projects-never-make-it-into-production/"><span class="underline">most of them</span></a> will fail, we need to carefully design our AI development methodology in order to remove the biggest failure risks as soon as possible: in other words, we need to quickly know when things are not going to work, and change direction when it’s the case.</p>

<p>But of course, this is not as easy as it sounds. Exactly like in startups, the most impactful AI projects seem impossible at the beginning, and only work as a result of perseverance and (sometimes absurd and obsessive) faith. A good example of this is <a href="https://venturebeat.com/2021/07/03/tesla-ai-chief-explains-why-self-driving-cars-dont-need-lidar/"><span class="underline">Tesla’s controversial choice to remove LiDAR and HD Maps</span></a> from their autonomous car perception pipeline: no one thought it would be possible at the time this decision was made, but the tremendous progress of AI since then shows that they may well succeed in this project.</p>

<p>What is the right balance between persistence and agility in AI? How can I execute an AI project in a way that:</p>

<ul>
  <li>
    <blockquote>
      <p>Limits as much as possible the risk of failure?</p>
    </blockquote>
  </li>
  <li>
    <blockquote>
      <p>Makes me quickly realize when I’m going off-track?</p>
    </blockquote>
  </li>
  <li>
    <blockquote>
      <p>Ensures that if I DO solve the research risks, the rest will follow, and the project will have the expected impact?</p>
    </blockquote>
  </li>
</ul>

<p><strong>In this blog post, I will discuss the 4 most important failure risks that I see in AI projects (problem fit, data fit, integration, and research), and will try to give concrete tips and methodology on how to mitigate them.</strong></p>

<h1 id="risk-1-problem-fit">Risk #1: Problem Fit</h1>

<p><img src="https://sebderhy.github.io/impactfulai/assets/img/2021-12-06-Risk-Management/media/image7.jpg" alt="" /></p>

<p>As explained in <a href="https://sebderhy.github.io/impactfulai/2021/11/01/Fall-in-love-with-the-problem,-not-the-solution.html"><span class="underline">my previous post</span></a>, one of the most important risks of failure of an AI project is to build a “<a href="https://www.ycombinator.com/library/8g-how-to-get-startup-ideas"><span class="underline">Solution In Search of a Problem</span></a>”. It can happen for many reasons: we may have been over-excited by a new paper or AI technique, and somehow managed to convince ourselves that it would solve our problem, or we may just have an incomplete understanding of the problem because we didn’t talk with the right people at the right time.</p>

<p>In my opinion, the easiest way to reduce this risk is to sit with the people who really feel this problem, and really understand the need. Product managers are in general the right people to have these conversations with, but if you can also access customers and salespeople, this is even better! Through these conversations, you will:</p>

<ul>
  <li>
    <blockquote>
      <p>Validate the need for this project</p>
    </blockquote>
  </li>
  <li>
    <blockquote>
      <p>Design the ideal solution (detached from any technical constraints at first)</p>
    </blockquote>
  </li>
  <li>
    <blockquote>
      <p>Decide on the reasonable trade-offs that could be made to reduce the project’s risk while maintaining a reasonable value (in other words, the equivalent of a <a href="https://en.wikipedia.org/wiki/Minimum_viable_product"><span class="underline">Minimum Viable Product</span></a>)</p>
    </blockquote>
  </li>
</ul>

<p>Ideally, the output of these discussions should be <strong>a document with project goals, inputs, expected outputs, and constraints</strong>.</p>

<p>On a side note, all these discussions obviously require work and time from the people you’ll discuss with, so you may argue that they don’t have the time to “help you” with your project at such an early stage. I believe it’s actually the opposite: if the project solves a real pain point, <strong>they are actually also helping themselves</strong>. This time investment actually reduces the AI/problem fit risk much more than the output document itself, which will probably change 30 times anyway. Those people are in general the ones whose interests are the most easily aligned with the company’s core metrics, so if they think they are wasting their time, this is a <strong>huge red flag that this project may not be a good use of your time</strong>! Actually, even if they do accept investing time, pay attention to their body language, and signs of impatience, it may mean that you are wasting your time too…</p>

<h1 id="risk-2-data-fit">Risk #2: Data Fit</h1>

<p>We hear all the time that “AI is all about data”, but people often tend to focus on data quantity rather than quality (I’ll explain what I mean by quality). Of course, you cannot do much without a decent amount of data, but <strong>it’s usually less than people think</strong> (I’ve found that in many cases, ~1000 data points are enough to start getting results). On the other hand, <strong>data “accuracy” (how close is your data from the data you will encounter in production) and “variance” (how much variability is there in the data) are critical to success in AI projects</strong>. More specifically, you will need to have data (for training AND testing) that reflects as closely as possible the cases you want to handle in production (including corner cases), but which also contains enough variance so that the AI model can learn to extract the patterns that really matter in your data.</p>

<p>However, getting the perfect “data fit” for your problem in one iteration is an almost impossible task. This is why many AI teams are now adopting a new methodology called “<a href="https://www.forbes.com/sites/forbestechcouncil/2021/12/03/the-onset-of-data-centric-ai-and-why-its-here-to-stay/?sh=554b9e1469cc"><span class="underline">Data-Centric AI</span></a>”, where they basically try to remove as much as possible the friction to acquiring new data (using for example <a href="https://app.livestorm.co/datagen/implementing-data-centric-methodology-with-synthetic-data?type=detailed"><span class="underline">synthetic data</span></a> which companies like <a href="https://www.datagen.tech/"><span class="underline">Datagen</span></a> can provide). While the term has been popularized by <a href="https://www.forbes.com/sites/gilpress/2021/06/16/andrew-ng-launches-a-campaign-for-data-centric-ai/?sh=3c5bddba74f5"><span class="underline">Andrew Ng</span></a>, most advanced companies in AI have been practicing this methodology for years now. My favourite implementation of this methodology is Tesla’s “<a href="https://gradientdescent.co/t/the-tesla-ai-team-s-data-engine/48"><span class="underline">Data Engine</span></a>”, which is shown below. Actually, this topic is such a game-changer in the world of AI that I’ll probably dedicate a future blog post to it.</p>

<p><img src="https://sebderhy.github.io/impactfulai/assets/img/2021-12-06-Risk-Management/media/image3.png" alt="" /></p>

<p>Source: slide from Andrej Karpathy’s (Tesla’s Director of AI) <a href="https://youtu.be/Ucp0TTmvqOE?t=7714"><span class="underline">presentation</span></a> at Tesla 2019 Autonomy Day</p>

<h1 id="risk-3-integration-with-other-teams">Risk #3: Integration with Other Teams</h1>

<p><img src="https://sebderhy.github.io/impactfulai/assets/img/2021-12-06-Risk-Management/media/image6.jpg" alt="" /></p>

<h2 id="plant-a-flag-on-the-roadmap">Plant a flag on the roadmap</h2>

<p>For a long time, I’ve thought that AI projects should live disconnected from product roadmaps, because of their inherent risk. Indeed, since we never know when (or if at all) an AI project is going to succeed, how on earth could we put its output on a roadmap that will afterwards be presented to customers, the company’s board, or maybe even announced publicly?! My conviction was that no one should put an AI-powered feature or product on a roadmap until the project has removed all of the main execution risks.</p>

<p>The problem with that approach is that once the algorithmic risks (i.e. the AI part) are lifted, you still have a very long way to go before seeing the AI in production and delivering actual value:</p>

<ul>
  <li>
    <blockquote>
      <p>Other teams don’t know much about your project, so they will suddenly need to deploy a lot of energy to both understand the problem, the solution that you built, and what you need exactly from them.</p>
    </blockquote>
  </li>
  <li>
    <blockquote>
      <p>You will also need these teams to change their plan, since deploying this feature was not initially on their roadmap. For example, you may need software development to deploy it, write tests, a QA team to check that it actually does what it should, etc… But they also had plans before you came, and no one likes to change their plans…</p>
    </blockquote>
  </li>
  <li>
    <blockquote>
      <p>The product team has probably committed to other features while you were developing this AI project, so they also won’t be very happy to delay their committed features to push yours.</p>
    </blockquote>
  </li>
  <li>
    <blockquote>
      <p>Most importantly, since your project did not appear on the roadmap, other teams may engage in structural changes while you develop, and suddenly make the deployment of your AI much harder. Worse, another team may have developed a work-around in the meantime, that may be much less effective than your solution, but will still be very difficult for you to replace.</p>
    </blockquote>
  </li>
</ul>

<p>It took me a long time to understand it, but I am now quite convinced that <strong>even AI teams should commit to “product” outputs.</strong> Yes, there is a risk of not delivering on your promises. Yes, that risk is high. But 1/ Every one who knows a bit about AI is aware of that risk, and 2/ putting an AI achievement on a roadmap before you know it’s feasible (the famous “<strong>fake it till’ you make it</strong>”) has a lot of advantages that I believe outweighs the risk of not delivering on your promises. Just to name a few:</p>

<ul>
  <li>
    <blockquote>
      <p>It will force other teams to get familiar with your project, collaborate with you on it when needed, and invest time to design it properly with you.</p>
    </blockquote>
  </li>
  <li>
    <blockquote>
      <p>It will also encourage them to plan and allocate resources for the moment your AI solution will be ready.</p>
    </blockquote>
  </li>
  <li>
    <blockquote>
      <p>Most importantly, it will put a positive pressure on you to <strong>build something end-to-end</strong>. Maybe it won’t work perfectly, and maybe you won’t be super proud of it at the beginning. But it will hopefully already provide some value to the company, and <strong>have the immense advantage of being fully integrated</strong>. This will make your life much easier later on when you’ll need to justify 2 additional months of work for the next version (the one with the real fancy AI in it) of this feature. We AI applied scientists don’t work well under pressure, but <strong>I believe that the lack of commitment, deadlines and expected deliverables sometimes also hinders us, and it’s time to change that</strong>. To continue my beloved parallel with startups, I have often heard that the best companies <a href="https://thenextweb.com/news/why-you-should-start-selling-your-product-before-it-exists"><span class="underline">sell their product before it exists</span></a>. Why should it be different with AI projects?</p>
    </blockquote>
  </li>
</ul>

<p><img src="https://sebderhy.github.io/impactfulai/assets/img/2021-12-06-Risk-Management/media/image4.png" alt="" /></p>

<h2 id="plan-interfaces-with-other-teams">Plan interfaces with other teams</h2>

<p>One of the biggest points of friction when pushing an AI model to production is integration with other parts of the system. Suddenly you need to have discussions with other teams about <strong>architecture:</strong> what is the exact format of your inputs/outputs? How will your algorithm be called? By whom? What parts run locally or on the cloud? etc… If you are lucky, these discussions will only generate some “adaptation” work of your algorithm in order to make it look exactly as it should. But if you’re less lucky, these questions may raise significant flaws in your system, and may require you to redesign it entirely. For example, you may assume that you will easily get a certain control or output from another component of the system, and realize later on that this level of output is actually something the other component cannot easily provide. A more obvious example is when your AI requires too much computational resources, and does not match the hardware constraints that you have in production.</p>

<p>Again, I believe the best way to reduce the integration risks is to have discussions with other teams at the beginning of your project on how this solution could be realistically integrated in the final product, which team should be responsible for what, etc… These discussions will also help the other teams involved in this project plan more precisely the resources they’ll need once your project gets more mature.</p>

<h1 id="risk-4-research">Risk #4: Research</h1>

<p>The research risk is critical, because <strong>only you</strong> can reduce it. The research phase consists in breaking your problems into subproblems, and building algorithms to solve each of them. Unfortunately, both of those tasks could be very hard, and this is where you’ll get to express all your AI and research talent. Exciting and scary at the same time right? Even though there is unfortunately no magic formula here, below are a few tips from my experience to help alleviate the risks involved with a problem or subproblem.</p>

<h2 id="connect-the-dots-backwards">Connect the dots backwards</h2>

<p><img src="https://sebderhy.github.io/impactfulai/assets/img/2021-12-06-Risk-Management/media/image5.png" alt="" /></p>

<p>If your AI pipeline is split into several parts, you should start by solving the LAST part, and then progress backwards in the pipeline to solve each block. This may seem counterintuitive at first sight, but there are two simple reasons behind this principle:</p>

<ol>
  <li>
    <blockquote>
      <p>You will be able to check early on that your outputs are acceptable in terms of format, quality, etc…</p>
    </blockquote>
  </li>
  <li>
    <blockquote>
      <p>You will naturally generate accurate specs for the previous blocks in your pipeline.</p>
    </blockquote>
  </li>
</ol>

<p>For example, let’s say you want to build an AI that recognizes a very small object in images. You may decide to first apply a <a href="https://en.wikipedia.org/wiki/Super-resolution_imaging"><span class="underline">super-resolution</span></a> algorithm to your input picture, in order to recognize the object more easily afterwards. But how big should the picture be? What is the required quality for this algorithm? These are questions you can only answer by first developing the recognition block first.</p>

<h2 id="look-at-things-from-a-different-angle">Look at things from a different angle</h2>

<p><img src="https://sebderhy.github.io/impactfulai/assets/img/2021-12-06-Risk-Management/media/image2.png" alt="" /></p>

<p>Sometimes, we can solve a problem by looking at it from a different and original perspective, typically by mathematically modeling things differently. For example, we can represent a surface quite naturally as a set of connected points in 3D (<a href="https://en.wikipedia.org/wiki/Polygon_mesh"><span class="underline">polygon mesh</span></a>), but we could also represent it as the 0 level set of a very smooth function of the 3D space f(x,y,z) = <a href="https://en.wikipedia.org/wiki/Signed_distance_function"><span class="underline">distance (potentially signed) of the point (x,y,z) to this surface</span></a>. This representation was one of the core ideas behind the paper <a href="https://www.youtube.com/watch?v=KOUSSlKUJ-A"><span class="underline">Kinect Fusion</span></a>, one of the most impactful papers in the world of 3D scanning and localization. This representation inspired the more recent breakthrough paper <a href="https://www.youtube.com/watch?v=JuH79E8rdKc"><span class="underline">NeRF</span></a> (although their representation is a bit different), which is able to render very realistic new views of a scene from several input views.</p>

<h2 id="map-research-risks-to-release-versions">Map research risks to release versions</h2>

<p>Once you have an initial assessment of the research risks involved in your project, try to sit again with the product team, and map them into a roadmap of feature releases. Ideally, you’d like to get to something like this:</p>

<table>
<thead>
<tr class="header">
<th></th>
<th>v1 (Minimum Viable)</th>
<th>v2 (creates significant value)</th>
<th>v3 (Super-great amazing holy grail release)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>AI/Market Fit</td>
<td>Required</td>
<td>Required</td>
<td>Required</td>
</tr>
<tr class="even">
<td>Integration</td>
<td>Required</td>
<td>Required</td>
<td>Required</td>
</tr>
<tr class="odd">
<td>Feature #1<br />
(Research Risk #1)</td>
<td>Required</td>
<td>Required</td>
<td>Required</td>
</tr>
<tr class="even">
<td>Feature #2<br />
(Research Risk #2)</td>
<td>Not required</td>
<td>Required</td>
<td>Required</td>
</tr>
<tr class="odd">
<td>Feature #3<br />
(Research Risk #3)</td>
<td>Not required</td>
<td>Not required</td>
<td>Required</td>
</tr>
<tr class="even">
<td>Feature #4<br />
(Research Risk #4)</td>
<td>Not required</td>
<td>Not required</td>
<td>Required</td>
</tr>
</tbody>
</table>

<p>Make sure you do not have more than 1 strong research risk before you get to a first product release. Indeed, if you have 10% chances to solve a risky problem in general, then you only have 1% chance to solve two risky AI problems in a row, so it’s most likely an unreasonable investment of your time.</p>

<h1 id="conclusion-should-i-pivot-or-persist">Conclusion: should I pivot or persist?</h1>

<p>Throughout this blog post, we’ve seen several ways to limit the risks of failure in AI, or at least make sure it happens as fast as possible when it’s inevitable. In particular, we’ve seen that many risks are not just technical but also business-related and organizational. However, the hardest question still remains: how do I know when to keep on trying, and when to change course in an AI project?</p>

<p>Here again, the same question holds for startups, but this time, we have a big advantage in AI over startups: our field is full of mathematics and modelisation. Now is the time to use them! Try to model mathematically your problems and subproblems, convince yourself theoretically or experimentally that something is feasible, or on the contrary try to find counterexamples when you feel your “proof” gets stuck. Simplify your problem into smaller ones that look solvable, and check that you can actually solve it. Try to break the problem into smaller pieces until you find the core resisting piece(s). Finally analyze (maybe even prove) WHY this piece is resisting, and what was the assumption you made there that turned out wrong. This “debug” process may help you make the right decision, but it may also actually help you find the key that you were missing to make your AI project work!</p>

  </div><a class="u-url" href="/impactfulai/2021/12/06/Risk-Management.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/impactfulai/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/impactfulai/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/impactfulai/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Let&#39;s make AI count as it should.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/sebderhy" target="_blank" title="sebderhy"><svg class="svg-icon grey"><use xlink:href="/impactfulai/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/sebderhy" target="_blank" title="sebderhy"><svg class="svg-icon grey"><use xlink:href="/impactfulai/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
