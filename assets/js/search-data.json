{
  
    
        "post0": {
            "title": "Why This Blog",
            "content": "Over the last 10 years, I’ve realized that applied research (and more specifically AI) is a double-edged sword. On the one hand, it can help you solve incredibly complex problems, and create an insane Return-On-Investment for companies. But on the other hand, according to a Venturebeat article (based on a Gartner report), only 20% of AI projects ever get deployed to production, and among those, only 40% are profitable! Unfortunately, these figures do not surprise me, as I’ve seen countless algorithmic and machine learning projects fail in my career. . I created this blog in order to analyze the reasons behind such failures, share experiences (mine and others’), and generate discussions that could eventually help maximize the impact of AI research in the real world. . Learning from the Startup World . In this blog, I will often tackle the questions raised above with an innovative angle: adapt lessons from the startup world to the AI conceptual world. Indeed, although we often hear about how startups can leverage AI to improve their business, no one to my knowledge took the opposite angle and explored how to leverage the widely studied and experienced startup world to improve AI’s impact on the world. . This idea may sound very weird at first sight, but anyone who looks closely at those two systems will be stricken by their similarities: a high risk of failure, an uncertain environment, the need for agility and speed, the urge to convince many stakeholders and align their interests, the necessity to find harmony between tech and business, … . Last but not least, the similarities between those 2 worlds particularly resonate with me, since I have been a VC investor and founder in the past, invested myself in a few startups, and generally spend a lot of time discussing and working with entrepreneurs. . Who is this blog for? . At a high level, this blog is for people that - like me - believe that AI’s impact should be much larger than it is today. More specifically, I think 3 types of people can learn from this blog: . Applied researchers like myself, who love reading papers and solving hard technical problems, but who are more motivated by their actual impact than their salary or implementing the latest cool AI paper (who said GAN ;-)?). . | Entrepreneurs and leaders, technical or not, on questions such as: “what to look for when recruiting?”, “what kind of ML infrastructure will make my teams most effective?”, “When to know when to stop an AI project”, etc… . | Investors or future entrepreneurs, on questions like “what are the problems in the world of AI today”, “who is tackling them and how”, etc… . | . Terminology . There are many close terminologies in the world of AI, and you will notice that I often use terms such as Artificial Intelligence, Data Science, Algorithms, Applied Research in an interchangeable manner… Some people may tell you that they are very different (I personally don’t think so), and there are many debates about differences between those fields. However, the truth is that in our case, the terminology doesn’t make such a difference, because they all relate to the same problem: how to handle risky projects that can have a huge impact, but whose results are quite unpredictable, and can often also very easily fail. Again, you can see here why I believe startups can teach us a lot on those projects. .",
            "url": "https://sebderhy.github.io/impactfulai/2021/10/22/Why-This-Blog.html",
            "relUrl": "/2021/10/22/Why-This-Blog.html",
            "date": " • Oct 22, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Fall In Love With The Problem. Not The Solution",
            "content": "(A big thanks to Elodie Tordjman from Smart-content for her great advice on this blog post) . Have you ever been given a task/project starting with: “Wouldn’t it be great if we had capability X? It would be a game-changer in so many aspects for our company!”. While this sounds like a very positive and energizing task, I’ve become more and more skeptical over the years of such tasks, because they lead you to build a “Solution In Search of a Problem”, a term popularized by Y Combinator to describe one of the most common startup pitfalls: . “The third mistake is to start with a solution instead of a problem. […] We see this so commonly at YC that we have a term for it. It’s called a “Solution In Search of a Problem,” or a SISP. And these are usually not great, because usually, you never actually find the problem. You’re much better off starting with a problem, and then looking for solutions.” . I’ll argue that what is true for a startup is actually also very true for AI algorithms. Actually, even if a task is properly defined as a problem, we often tend to jump on building a solution, rather than investigating the pain point, simply because it is our comfort zone: after all, we’ve all been trained and hired for our “problem-solving” skills right? Who wants to have a “problem-digger”? . This post will be divided into 2 parts: . How this SISP trend materializes in the AI world (both academic and industrial). . | 7 practical tips to make sure your AI solution stays focused on solving a real and meaningful problem. . | A look at the industry - it happens more than you’d think! . An example from the industry . In 2011, Microsoft released a consumer gaming accessory called Kinect that enabled people to play by moving freely in front of their camera. In addition to being a huge commercial success, it was also a very hard technological achievement. The Kinect team not only managed to build a brilliant gesture detection algorithm, but also made a huge hardware achievement: in order to provide a truly seamless experience, Microsoft realized that they would need a special type of camera, called “depth cameras” (a camera able to estimate the 3D location of each pixel). They found a way to miniaturize them, make them much cheaper, and manufacture them at scale, partnering with an Israeli startup called Primesense, which was later acquired by Apple in a surprising turn of events. Kinect is in my opinion the perfect example of a problem-driven technological breakthrough, and this is in my opinion why it was so successful. . However, as is very often the case, this technological achievement somehow gave birth to many solution-driven technological failures. Suddenly, other big companies realized that these cameras were able to achieve what regular cameras couldn’t and that these cameras would “open doors to many amazing new applications for smartphone and tablet cameras”. Google opened a project called Tango, Intel a project called RealSense, and Apple acquired Primesense. . Fast-forward 10 years later, what happened to these projects? Well, the results are unfortunately not brilliant. Google managed to manufacture a few devices, but didn’t achieve any commercial success with Tango, and shut down the program. Intel manufactured a few RealSense products, built a lot of software, but finally didn’t reach any meaningful commercial success and recently announced that they will be shutting down their RealSense department. Apple did achieve commercial success with iPhones and iPad that have depth cameras integrated, but never really found a “killer-app”. To my knowledge, the most important use-case of the iPhone depth camera is currently FaceID, which allows you to unlock your smartphone with your face. And yes, FaceID is cool, but will it be remembered as a game-changing technology? Is it so much better than fingerprint-based or regular-camera-based identification? My personal feeling is that Apple successfully sold depth-equipped smartphones not because of the depth cameras, but because of other features (and most importantly… Because it was the new iPhone!). . An example from the academy . In 2017, some researchers from Google introduced the Transformers architecture, and it was a huge breakthrough in the world of NLP/NLU (Natural Language Processing/Understanding) because it enabled a dramatic performance boost on almost every language-related AI task. But exactly like in my previous examples, after the seminal paper introducing Transformers, many people tried to apply Transformers to other domains, and in particular computer vision, and even managed to show some slight improvements on ImageNet classification. However, in computer vision, we already have an architecture that works really well: Convolutional Neural Networks (CNN). Actually, an amazing recent paper called “ResNet Strikes back” proved that the most trivial CNN architecture can reach the same level of performance as Transformer-based architectures if they are trained correctly. Of course, this doesn’t mean that transformer will never be useful for images, but why not rather spend time to leverage transformers in much harder AI problems where CNNs do not work well, such as audio processing, geometric deep learning, few-shots classification, 3D mesh processing, etc…? . That being said, I have to admit that I’m being a bit unfair with the AI academic world. Maybe academic research SHOULD be solution-driven and not problem-driven. Some problems in the world are so hard to fix that the only way to solve them is by trying lots of things and “connecting the dots backward” (as Steve Jobs famously said). The world obviously needs some solution-driven research to accomplish great things, but people engaging in this path should be aware that their impact will at best be in the long run, at worst be null. . 7 tips to make sure you are building a problem-driven AI . Get business insights about the problem . Whenever you receive a task, it is very likely that the person giving you the task (e.g. an Algorithm Team Lead) is not the real source of the task. More likely, they heard from other people in the company about a painful problem that needs to be addressed and thought it could be a good fit for your skills. . Therefore, your first goal should be to become the most knowledgeable person about this problem: go and talk to the people that really FEEL the pain. Very often, this should involve talking to customers, but if it’s difficult for any reason, try to at least ask as much about it to your Product Manager, or customer-facing people. In particular, I recommend this user interview framework from Startup School when trying to understand a problem: . What’s the hardest part about the problem? . | Tell me about the last time you found this problem? . | Why was that hard? . | What, if anything, have you done to try to solve this problem? . | What are the issues with the solutions you’ve tried? . | . Another famous and in my opinion very efficient framework to understand the root cause of a problem is to ask the 5 whys. This will really help you get to the core reasons behind your problem, and I found that it can be particularly helpful later on when you’ll need to find creative solutions to solve the problem. . Check that the problem is correctly prioritized . Once you understand the problem, try to get a very rough sense of its worth. How often does the company lose a deal because of this? How much engineering time would be saved if it were solved? How important is this problem compared to others that you could work on? . This is actually a very tricky part. First, because prioritization requires having the big picture, and this is something you don’t always have. In addition, as an AI scientist, you usually don’t have the luxury to decide whether a task should or should not be prioritized. However, you should always have the ability (it’s even a duty!) to discuss with the person that gave you this task, and try to change their mind if you don’t agree with them. Making correct prioritization is probably one of the toughest job leaders have, so help them be better at their job: they will appreciate it, and you will avoid working in vain. I’ve seen too many AI scientists making amazing solutions that never made it to production because they turned out not to be so important at the end, and hence the deployment task never got prioritized. . Prove this problem really requires you . Especially if you’ve done the 5 whys exercise, you should now see the deep root causes of the problem you are trying to solve. At that point, you may realize that the main problem might be solved by something very different from what you’ve been originally told. It could potentially be anything: a different marketing strategy, a better internal process, or simply the integration of some external software. . The most frequent example is when you find a third-party company that already offers a product that solves your problem. Of course, it will cost money, but unless the third-party company has a VERY bad pricing strategy, this solution should be a better deal than building it in-house from scratch. So before you start writing a single line of code, make sure that you’ve done serious market research, and that a commercial product suiting your needs does not already exist. . Build a good evaluation pipeline . If you’ve done your research correctly on the problem understanding part, you should already have a good idea of what an ideal solution looks like. You may even have a few brilliant ideas on how to tackle the problem. However, it is very important that you refrain from coding your brilliant solution, otherwise, you’ll have no idea how good it is, and unfortunately, no one will be convinced that it works just because it comes from your brilliant mind, or because it is based on the latest CVPR award-winning paper. . At this stage, you should design a robust and informative way to evaluate any solution to the problem you’re solving: . Quantitative performance tests: metrics that really characterize how good your solution is. In general, one needs to define several metrics that are anti-correlated, such that it is very hard to increase one without hurting the other. . | Qualitative performance tests: even though it’s important to define the algorithm’s quality through clear metrics, these metrics need in general to be complemented with human-based judgment. For example, if you are building an AI that generates images, and want to evaluate how good-looking these images are, you can use metrics such as FID or PPL, but at some point, someone will have to take a look at them (spoiler: most of the time, YOU will have to!!). . | Divide the performance tests above into test sets that . Represents as faithfully as possible the data you’ll have in production . | Help you find your solution’s strengths and weaknesses before being deployed . | . | . Needless to say that the process to test a given solution and visualize its results should be as straightforward and convenient as possible (one push button, ideally). It will save you a lot of precious time later when you’ll need to iterate. On this topic, I highly recommend tools such as Tensorboard and Weights &amp; Biases for tracking machine learning results, or QA-Board for more generic algo projects (QA-Board has in particular an amazing image comparison tech). You may also want to use tools such as Kubeflow that enable you to manage and run many machine learning experiments in parallel. I’ll probably make a separate blog post on MLOps, so that we can dive more into those tools and the pain points they solve. . Interestingly, this idea that one should write problem-defining tests before coding the solution that will pass those tests is very famous and widely adopted in the world of software development. It’s called test-driven development, and Robert Martin (Uncle Bob) has a wonderful presentation on this topic. For some reason, its adoption in the world of AI is still relatively low. . Think big, start small . The previous company I worked for (Via Transportation) had an amazing catchphrase for the R &amp;D teams, that I try to remember whenever I envision a new challenge: “think big, start small”. Now that you’ve set up a great testing environment, your next step is to build a baseline, i.e. the SIMPLEST algorithm you can write in your test environment that will get you ANY performance score (yes, this score does need to be great). Don’t try to be too sophisticated there, the goal is to have something to compare to, and to get some convincing evidence that the complicated algorithm you will build next really had to be complicated. . Iterate fast . Once you have a baseline and a good evaluation environment, the algo fun can finally begin! This is the place where your research talent comes most into play: read papers, get interesting insights about the data and your problem, implement things, etc… However, keep in mind that it’s not just about being smart, but also being able to iterate fast. Here again, the resemblance with startups is stunning: because of the very uncertain environment of algorithm research, it is often VERY worth spending time on the iteration speed process rather than figuring out the next thing you want to try. Typically, do not train a network for 7 days if you have no idea whether it’s going to work at the end. . Move to prod as fast as possible . Ok, so you’ve finally got your first good-enough algorithm, but at this stage, chances are you’re still not satisfied… There are so many things you haven’t optimized yet! So many other ideas you’d like to experiment! But this is also where you need the discipline to focus on your problem (the one you fell in love with, remember :)?). Even though your algorithm seems pretty basic and very improvable, you should try to push it to production as soon as possible, since it is probably already better than what exists today. . The reasons for this are: . The process to move things to prod is slow and painful. You’ll probably have plenty of time to improve your algorithm during the deployment process, and in most cases, you will be able to update your model/code without problems. . | The process of deploying will likely teach you a lot about the constraints your solution needs to fit in, and you might suddenly realize that some key performance aspect of your algorithm was not properly taken into account by your evaluation metrics/pipeline: in other words, you’re back to step 4 ;-). . | Once you’ve made the full cycle of moving to prod, you should be able to iterate and deploy improvements on a regular basis. This will make your work much more visible, and if you care about the problem you’re solving, you’ll feel great that your work actually makes someone else’s life better. . | Conclusion - Wait, is this really my job?!! . You may have noticed that most of the tips in this article don’t require reading lots of papers, implementing super-fancy-math-based AI algorithms, etc… So I think that it’s important for me to clarify a few things. . I didn’t write a lot about step #6 (will probably explain more about fast iteration in a future post), but it is probably the hardest, longest, and most uncertain part of an AI development process, so in practice, you can expect to spend a significant time on researching a good solution for your problem. But don’t forget the other steps! . | In some organizations, other people (e.g. product managers) will perform steps 1 to 3, so that you can focus on others that require more coding. Therefore, if you only want to code, some organizations may help you do that. . | That being said, let’s face the ugly truth: real-life impactful AI is not academic research, and it’s not even a Kaggle competition. If you are intrinsically motivated by the value you’re creating for the world, and the cause you are helping move forward, you’ll eventually thrive, be recognized for your work, and find huge satisfaction in seeing the impact of your work. On the other hand, if you only want to do the fun and interesting parts of AI, write a paper or add a new technical skill to your resume, then you are probably better off doing academic (Vs “applied”) research, which is actually also a great path that I highly respect, but it’s a very different one! . |",
            "url": "https://sebderhy.github.io/impactfulai/2021/10/22/Fall-in-Love-with-the-Problem.-Not-the-Solution.html",
            "relUrl": "/2021/10/22/Fall-in-Love-with-the-Problem.-Not-the-Solution.html",
            "date": " • Oct 22, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://sebderhy.github.io/impactfulai/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://sebderhy.github.io/impactfulai/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". My name is Sebastien Derhy, I am originally from France (Paris), but live in Tel-Aviv since July 2014. I’ve always been passionate about the intersection between technology (in particular deep learning and computer vision), research, and business. This is one of the reasons creating this blog was so important to me. . I am currently leading Algorithms at Datagen, a startup helping computer vision scientists work seamlessly in a data-centric R&amp;D cycle using synthetic data. . My past experiences include: . Navigation Intelligence Team Leader at Via Transportation | Algorithm Team Leader at Samsung Israel Research Center | COO &amp; Co-founder of Fitterli, a startup that aimed at leveraging depth cameras in smartphones for online shopping | VC at Elaia Partners, one of the leading European VCs, first investors of several French unicorns: Criteo (NASDAQ: , CRTO), Shift Technology, and Mirakl. | Visiting Researcher at the Technion, where I worked at the GIP lab under the supervision of Ron Kimmel on a Gesture-based Tetris game. | . I hold an MSc in Applied Mathematics from Ecole Polytechnique and an MSc in Entrepreneurship from HEC. .",
          "url": "https://sebderhy.github.io/impactfulai/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://sebderhy.github.io/impactfulai/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}